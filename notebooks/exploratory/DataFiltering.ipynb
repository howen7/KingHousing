{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing 3 Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parcel = pd.read_csv('../../references/EXTR_Parcel.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_csv('../../references/EXTR_ResBldg.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = pd.read_csv('../../references/EXTR_RPSale.csv', encoding = \"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering for single family homes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real['DocumentDate'] = pd.to_datetime(df_real['DocumentDate'], format=\"%m/%d/%Y\")\n",
    "df_real['year'] = pd.DatetimeIndex(df_real['DocumentDate']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set property type to 2,3,11 which are single family units\n",
    "#set to principal use to 6 which is RESIDENTIAL   \n",
    "#set year to 2019 for most recent data\n",
    "# set propertyclass to 8 and 7 which includes only houses\n",
    "df_real = df_real.loc[(df_real.PropertyType.isin([2,3,11])) & \n",
    "                           (df_real.SalePrice > 250000) & \n",
    "                           (df_real.SalePrice < 3000000) &\n",
    "                           (df_real.PrincipalUse == 6) & \n",
    "                           (df_real.year == 2019) &\n",
    "                           (df_real.PropertyClass.isin([8,7]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a UniqueID accross all dataframes to combine later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df_parcel, df_res, df_real]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_list:\n",
    "    i.Minor = i.Minor.apply(lambda x: str(x).zfill(4))\n",
    "    i.Major = i.Major.apply(lambda x: str(x).zfill(6))\n",
    "    i['UniqueID'] = pd.to_numeric(i['Major'] + i['Minor']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicated values of unique id in and keeping most recent sale\n",
    "df_real = df_real.sort_values('DocumentDate').drop_duplicates('UniqueID', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df_res.drop_duplicates(subset = 'UniqueID', keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making UniqueID column the index for all the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.set_index(keys = 'UniqueID', drop=True, inplace=True)\n",
    "df_parcel.set_index(keys = 'UniqueID', drop=True, inplace=True)\n",
    "df_real.set_index(keys = 'UniqueID', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating the Dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([df_real, df_parcel.reindex(df_real.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([test_df, df_res.reindex(test_df.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes duplicated columns\n",
    "df_combined = df_combined.loc[:,~df_combined.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chosen = df_combined[['SalePrice',\n",
    " 'SqFtTotLiving',\n",
    " 'SqFtOpenPorch',\n",
    " 'WfntFootage', \n",
    " 'WfntLocation',\n",
    " 'FinBasementGrade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-b1d81b20ac6e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_chosen.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_chosen.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chosen.to_json('../../src/data/combined.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dummy columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cont = ['SalePrice',\n",
    "        'SqFtTotLiving',\n",
    "        'SqFtOpenPorch',\n",
    "        'WfntFootage',\n",
    "        'FinBasementGrade']\n",
    "\n",
    "df_cont = df_chosen[cont]\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "catagory = ohe.fit_transform(df_chosen.drop(cont,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ohe.get_feature_names([\n",
    " 'WfntLocation',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.DataFrame(index = df_chosen.index , data = catagory.todense(), columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_catagories = pd.concat([df_cont, df_cat.reindex(df_cont.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_catagories.to_json('../../src/data/combined_onehot.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
